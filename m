Return-Path: <linux-kernel-owner+willy=40w.ods.org@vger.kernel.org>
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S262007AbUC1Q44 (ORCPT <rfc822;willy@w.ods.org>);
	Sun, 28 Mar 2004 11:56:56 -0500
Received: (majordomo@vger.kernel.org) by vger.kernel.org id S262017AbUC1Q44
	(ORCPT <rfc822;linux-kernel-outgoing>);
	Sun, 28 Mar 2004 11:56:56 -0500
Received: from ns.suse.de ([195.135.220.2]:35740 "EHLO Cantor.suse.de")
	by vger.kernel.org with ESMTP id S262007AbUC1Q4x (ORCPT
	<rfc822;linux-kernel@vger.kernel.org>);
	Sun, 28 Mar 2004 11:56:53 -0500
Date: Sun, 28 Mar 2004 18:53:47 +0200
Message-ID: <s5hwu549alg.wl@alsa2.suse.de>
From: Takashi Iwai <tiwai@suse.de>
To: dipankar@in.ibm.com
Cc: "Paul E. McKenney" <paulmck@us.ibm.com>,
       Arjan van de Ven <arjanv@redhat.com>, Robert Love <rml@ximian.com>,
       Andrew Morton <akpm@osdl.org>, linux-kernel@vger.kernel.org
Subject: Re: [PATCH] RCU for low latency (experimental)
In-Reply-To: <20040324234643.GD12035@in.ibm.com>
References: <1080038105.5296.8.camel@laptop.fenrus.com>
	<20040323123105.GI22639@dualathlon.random>
	<20040323124002.GH3676@in.ibm.com>
	<20040323125044.GL22639@dualathlon.random>
	<20040324172657.GA1303@us.ibm.com>
	<20040324175142.GW2065@dualathlon.random>
	<20040324213914.GD4539@in.ibm.com>
	<20040324225326.GH2065@dualathlon.random>
	<20040324231145.GB12035@in.ibm.com>
	<20040324233430.GJ2065@dualathlon.random>
	<20040324234643.GD12035@in.ibm.com>
User-Agent: Wanderlust/2.10.1 (Watching The Wheels) SEMI/1.14.5 (Awara-Onsen) FLIM/1.14.5 (Demachiyanagi) APEL/10.6 MULE XEmacs/21.4 (patch 13) (Rational FORTRAN) (i386-suse-linux)
MIME-Version: 1.0 (generated by SEMI 1.14.5 - "Awara-Onsen")
Content-Type: text/plain; charset=US-ASCII
Sender: linux-kernel-owner@vger.kernel.org
X-Mailing-List: linux-kernel@vger.kernel.org

At Thu, 25 Mar 2004 05:16:43 +0530,
Dipankar Sarma wrote:
> 
> On Thu, Mar 25, 2004 at 12:34:30AM +0100, Andrea Arcangeli wrote:
> > On Thu, Mar 25, 2004 at 04:41:45AM +0530, Dipankar Sarma wrote:
> > > That was not 16 callbacks per tick, it was 16 callbacks in one
> > > batch of a single softirq. And then I reschedule the RCU tasklet
> > 
> > sorry so you're already using tasklets in current code? I misunderstood
> > the current code then.
> 
> +               if (count >= rcumaxbatch) {
> +                       RCU_plugticks(cpu) = rcuplugticks;
> +                       if (!RCU_plugticks(cpu))
> +                               tasklet_hi_schedule(&RCU_tasklet(cpu));
> +                       break;
> +               }

it seems count is never incremented in your patch...
or am i missing something?

anyway, i confirmed that with the original krcud patch the latency
with dcache flood can be eliminated.

for the non-preemptive case, rcu_bh_callback_limit() should return
bhlimit always, though.  otherwise cond_resched() isn't called in the
callback loop properly.


Takashi
